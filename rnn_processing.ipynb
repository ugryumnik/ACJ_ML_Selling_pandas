{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "686bb87e-8f43-4434-8dab-3e461428bc98",
   "metadata": {},
   "source": [
    "Готовим датасет для RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebb6715-034f-4f5a-92ac-c1d8da3003d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e70ad4ef-774c-4069-a99f-3e3f02e6f945",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Библиотеки\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from rnn_utils import read_parquet_dataset_from_local, create_padded_buckets, transform_actions_to_sequences, seed_everything\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24d83d15-ac1f-467a-b39e-0a3035a45644",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir constants\n",
    "\n",
    "!mkdir buckets\n",
    "\n",
    "!mkdir partitions\n",
    "!mkdir partitions/train\n",
    "!mkdir partitions/val\n",
    "!mkdir partitions/test\n",
    "!mkdir partitions/train_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "039e508b-0537-44c5-92c4-d4fd93d3eaa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Считываем данные\n",
    "df = pd.read_csv('data/dataset_fixed.csv')\n",
    "sample_submission = pd.read_csv('data/submission_example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0950955a-db0f-46bd-849a-999e4ebfaa38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Необходимые пороги\n",
    "start_train_threshold = '2020-03-01' # Должно быть хотя бы одно привлечение позже этой даты, иначе партнер уже \"ушел\"\n",
    "train_threshold = '2020-06-01' # Конец трейна (привлечения позже этой даты не подаем в X_train)\n",
    "val_threshold = '2020-09-01' # Конец валидации (привлечения позже этой даты не подаем в X_val)\n",
    "test_threshold = '2020-12-01' # Конец теста (привлечения позже этой даты не подаем в X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7ee74f-498b-47e1-9e31-b773fb5e7a4e",
   "metadata": {},
   "source": [
    "# Base Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "013d54a5-7910-488f-b3d6-813ac88c6cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partner</th>\n",
       "      <th>client</th>\n",
       "      <th>type</th>\n",
       "      <th>time</th>\n",
       "      <th>start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122027</td>\n",
       "      <td>5579</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>2019-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270277</td>\n",
       "      <td>5585</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>2020-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238679</td>\n",
       "      <td>5586</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118398</td>\n",
       "      <td>5587</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>2019-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10402</td>\n",
       "      <td>5588</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130813</th>\n",
       "      <td>4639</td>\n",
       "      <td>333509</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>2020-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130814</th>\n",
       "      <td>226754</td>\n",
       "      <td>333510</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-07-19</td>\n",
       "      <td>2020-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130815</th>\n",
       "      <td>2645</td>\n",
       "      <td>333511</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>2020-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130816</th>\n",
       "      <td>145720</td>\n",
       "      <td>333512</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-07-25</td>\n",
       "      <td>2019-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130817</th>\n",
       "      <td>281273</td>\n",
       "      <td>333513</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-07-19</td>\n",
       "      <td>2020-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130818 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        partner  client  type       time start_time\n",
       "0        122027    5579     3 2019-06-25 2019-02-01\n",
       "1        270277    5585     3 2020-05-07 2020-04-01\n",
       "2        238679    5586     3 2020-02-27 2020-02-01\n",
       "3        118398    5587     3 2020-03-26 2019-09-01\n",
       "4         10402    5588     0 2019-04-05 2019-01-01\n",
       "...         ...     ...   ...        ...        ...\n",
       "130813     4639  333509     4 2020-07-20 2020-03-01\n",
       "130814   226754  333510     3 2020-07-19 2020-05-01\n",
       "130815     2645  333511     4 2020-07-23 2020-05-01\n",
       "130816   145720  333512     0 2020-07-25 2019-05-01\n",
       "130817   281273  333513     3 2020-07-19 2020-04-01\n",
       "\n",
       "[130818 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# object -> datetime\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df['start_time'] = pd.to_datetime(df['start_time'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e00d1a73-cf61-405e-9bda-924407288f99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Формируем фичи по датам\n",
    "\n",
    "df['year'] = df['time'].dt.year\n",
    "df['month'] = df['time'].dt.month - 1\n",
    "df['day_of_week'] = df['time'].dt.day_of_week\n",
    "\n",
    "\n",
    "df['year_start'] = df['start_time'].dt.year\n",
    "df['month_start'] = df['start_time'].dt.month - 1\n",
    "df['day_of_week_start'] = df['start_time'].dt.day_of_week\n",
    "\n",
    "df['time_col'] = df['time'] # Сохраняем оригинальное время (пригодится для сортировки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e65eee5f-e45d-4cab-ae26-228080494209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Нарезаем датасет на train/train_full/val/test\n",
    "# Train full - полная выборка, нужна для обучения без валидации (это осуществяется непосредственно перед инференсом)\n",
    "\n",
    "X_train = df[df.time < train_threshold] # 2019-03-01 - 2020-03-01\n",
    "X_val = df[(df.time.min() + DateOffset(months=3) < df.time) & (df.time < val_threshold)] # 2019-06-01 - 2020-06-01\n",
    "\n",
    "X_train_full = df[df.time < val_threshold] # 2019-03-01 - 2020-09-01\n",
    "\n",
    "X_test = df[df.time < test_threshold] # 2019-03-01 - 2020-12-01\n",
    "X_test = X_test[X_test.time > df.time.min() + DateOffset(months=3)] # 2019-06-01 - 2020-12-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cc99c27-7247-4748-a4fd-f104df82f979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_diffs(x): # Сколько времени с предыдущего привлечения до текущего прошло\n",
    "    return [-1] + (np.array(x[:-1])-np.array(x[1:])).tolist()\n",
    "\n",
    "\n",
    "def add_features(data, has_target, last_attraction_threshold=None, \n",
    "                 end_threshold=None, target_end_threshold=None, num_partition=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Добавляет фичи в данные\n",
    "    :param data: pd.DataFrame (DataFrame с привлечениями)\n",
    "    :param has_target: bool (Есть таргет или нет)\n",
    "    :param last_attraction_threshold: str/pd.DateTime (хоть одно привлечение должно быть позже этой даты,\n",
    "    иначе считаем партнера уже ушедшим)\n",
    "    :param end_threshold: str/pd.DateTime (берем привлечения до этой даты)\n",
    "    :param target_end_threshold: str/pd.DateTime (таргет определяем по периоду от end_threshold до этой даты)\n",
    "    :param num_partition: int, optional (Номер партиции)\n",
    "    :return: pd.DataFrame, pd.DataFrame - фичи и таргет (для теста только фичи)\n",
    "    \"\"\"\n",
    "                \n",
    "    data = data[data.time < end_threshold]\n",
    "    \n",
    "    \n",
    "    # Оставляем только не ушедших партнеров\n",
    "    max_time_of_attraction = data.groupby('partner').agg({'time': 'max'})\n",
    "    appropriate_partners = max_time_of_attraction[max_time_of_attraction.time>=last_attraction_threshold].index\n",
    "    data = data[data.partner.isin(appropriate_partners)]\n",
    "    \n",
    "    # Сколько дней осталось до порога (начиная с которого идет таргет)\n",
    "    data['time_left'] = (pd.to_datetime(end_threshold) - data['time']).astype(int)//10**9 / 3600 // 24\n",
    "    \n",
    "    # Переводим в дни\n",
    "    data['start_time'] = data['start_time'].astype(int)//10**9 / 3600 // 24\n",
    "    \n",
    "    if has_target:\n",
    "        # Если в нужный период есть привлечение, то 0, иначе 1\n",
    "        y = pd.DataFrame({'partner': np.unique(data.partner), 'score': 0})\n",
    "        y.loc[y.partner.isin(np.unique(df[(end_threshold <= df.time) & ( df.time < target_end_threshold)]['partner'])), 'score'] = 1\n",
    "    \n",
    "    \n",
    "    data = data.sort_values(['partner', 'time_col', 'client'], ascending=True)\n",
    "    \n",
    "    # # Номер привлечения\n",
    "    # data['num_attraction'] = data.groupby('partner')['time'].transform(lambda x: list(range(1, len(x)+1))).values\n",
    "    # # Всего привлечений\n",
    "    # data['count_attractions'] = data.groupby('partner')['num_attraction'].transform('max')\n",
    "    \n",
    "    if num_partition is not None:\n",
    "        # Записываем номер партиции\n",
    "        data['partition'] = num_partition\n",
    "        y['partition'] = num_partition\n",
    "    \n",
    "    # # Дней с прошлого привлечения\n",
    "    # data['diff'] = data.groupby('partner')['time_left'].transform(get_diffs).values\n",
    "    \n",
    "        \n",
    "    if has_target:\n",
    "        return data, y\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede74aea-07a1-4bc2-85e2-22c86da1828c",
   "metadata": {},
   "source": [
    "# Train and Train_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf919fbb-2d43-4bbf-baf4-8be98ca071e7",
   "metadata": {},
   "source": [
    "Создадим Train и Full train с аугментацией (нарезая датасет на части).\n",
    "\n",
    "Пример:\n",
    "\n",
    "Партиция 0: данные с 2019-03-01 по 2020-02-28, таргет с 2020-03-01 по 2020-05-31\n",
    "\n",
    "Партиция 1: данные с 2019-02-15 по 2020-02-13, таргет с 2020-02-15 по 2020-05-16\n",
    "\n",
    "Партиция 2: данные с 2019-02-01 по 2020-01-29, таргет с 2020-02-01 по 2020-05-01\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ad29e80-3077-403a-a9fa-7f905daf00a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = DateOffset(days=15) # С каким промежутком нарезать\n",
    "num_partitions = 26 # Сколько партиций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edeb1a7d-e399-49c6-a3f5-da7964c73ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((751744, 14), (65114, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_list = []\n",
    "y_train_list = []\n",
    "\n",
    "\n",
    "for num_partition in range(num_partitions):\n",
    "    # Пороги для партиции\n",
    "    start_train_threshold_new = pd.to_datetime(start_train_threshold) - delta * num_partition\n",
    "    train_threshold_new = pd.to_datetime(train_threshold) - delta * num_partition\n",
    "    val_threshold_new = pd.to_datetime(val_threshold) - delta * num_partition\n",
    "    \n",
    "    # Данные для одной партиции\n",
    "    X_train_part, y_train_part = add_features(X_train.copy(), has_target=True, last_attraction_threshold=start_train_threshold_new, \n",
    "                                end_threshold=train_threshold_new, target_end_threshold=val_threshold_new,\n",
    "                               num_partition=num_partition)\n",
    "    \n",
    "    X_train_list.append(X_train_part)\n",
    "    y_train_list.append(y_train_part)\n",
    "    # print(X_train_part.shape)\n",
    "    # print(y_train_part.score.value_counts().to_dict())\n",
    "\n",
    "# Объединяем партиции в единый датасет\n",
    "X_train = pd.concat(X_train_list, axis=0, ignore_index=True)\n",
    "y_train = pd.concat(y_train_list, axis=0, ignore_index=True)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcea8b02-df72-4632-bce8-648c9ae36fe4",
   "metadata": {},
   "source": [
    "Теперь то же самое для full train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe11039c-b310-4e3d-8d65-ca58a2ee8a81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1145753, 14), (80188, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full_list = []\n",
    "y_train_full_list = []\n",
    "\n",
    "\n",
    "for num_partition in range(num_partitions):\n",
    "    start_train_threshold_new = pd.to_datetime(train_threshold) - delta * num_partition\n",
    "    train_threshold_new = pd.to_datetime(val_threshold) - delta * num_partition\n",
    "    val_threshold_new = pd.to_datetime(test_threshold) - delta * num_partition\n",
    "\n",
    "    \n",
    "    X_train_part, y_train_part = add_features(X_train_full.copy(), has_target=True, last_attraction_threshold=start_train_threshold_new, \n",
    "         end_threshold=train_threshold_new, target_end_threshold=val_threshold_new,\n",
    "                               num_partition=num_partition)\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train_full_list.append(X_train_part)\n",
    "    y_train_full_list.append(y_train_part)\n",
    "    # print(X_train_part.shape)\n",
    "    # print(y_train_part.score.value_counts().to_dict())\n",
    "    \n",
    "    \n",
    "X_train_full = pd.concat(X_train_full_list, axis=0, ignore_index=True)\n",
    "y_train_full = pd.concat(y_train_full_list, axis=0, ignore_index=True)\n",
    "X_train_full.shape, y_train_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2462975-a711-4b52-ac2f-94f1ebdd0cda",
   "metadata": {},
   "source": [
    "# Val and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc06b8d4-b960-456a-8fc6-c8758d1b7767",
   "metadata": {},
   "source": [
    "Теперь валидация и тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1441cdcc-845a-42c0-8f46-85eba4fc268f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_val, y_val = add_features(X_val.copy(), has_target=True, last_attraction_threshold=train_threshold,\n",
    "                    end_threshold=val_threshold, target_end_threshold=test_threshold)\n",
    "\n",
    "X_test = add_features(X_test.copy(), has_target=False, last_attraction_threshold=val_threshold,\n",
    "                    end_threshold=test_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7894b7ab-6644-4e51-b9a9-55f5b0d8748f",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf80926-af36-4157-98a0-b5cd88f2f934",
   "metadata": {},
   "source": [
    "Выберем нужные нам фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43b021de-6c95-4c28-bf43-19df3e1657f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['partner', 'client', 'type', 'time', 'start_time', 'year', 'month',\n",
       "       'day_of_week', 'year_start', 'month_start', 'day_of_week_start',\n",
       "       'time_col', 'time_left', 'partition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "423b54ae-cf24-42cf-aec2-ef86ba7f74db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partner</th>\n",
       "      <th>client</th>\n",
       "      <th>type</th>\n",
       "      <th>time</th>\n",
       "      <th>start_time</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>year_start</th>\n",
       "      <th>month_start</th>\n",
       "      <th>day_of_week_start</th>\n",
       "      <th>time_col</th>\n",
       "      <th>time_left</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>211585</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-11-24</td>\n",
       "      <td>18109.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-11-24</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>291300</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>18109.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>219861</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-12-07</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-12-07</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   partner  client  type       time  start_time  year  month  day_of_week  \\\n",
       "0        1  211585     4 2019-11-24     18109.0  2019     10            6   \n",
       "1        1  291300     4 2020-05-29     18109.0  2020      4            4   \n",
       "2       30  219861     4 2019-12-07     18201.0  2019     11            5   \n",
       "\n",
       "   year_start  month_start  day_of_week_start   time_col  time_left  partition  \n",
       "0        2019            7                  3 2019-11-24      190.0          0  \n",
       "1        2019            7                  3 2020-05-29        3.0          0  \n",
       "2        2019           10                  4 2019-12-07      177.0          0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "710d07ae-d19a-455e-bd27-198a70c26d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Сохраним X_train без аугментации (пригодится для подсчета характеристик, основанных на распределении трейна)\n",
    "\n",
    "if 'partition' in X_train:\n",
    "    X_train_base = X_train[X_train.partition == 0].drop(columns=['partition'])\n",
    "else:\n",
    "    X_train_base = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5b083b4-22b4-4c08-9f7d-307c9d998d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_col = 'time_col'\n",
    "# instance_col = 'partner'\n",
    "\n",
    "# num_cols = ['time', 'diff', 'num_attraction']\n",
    "# cat_cols = ['month', 'day_of_week']\n",
    "\n",
    "# fixed_num_cols = ['start_time', 'count_attractions']\n",
    "# fixed_cat_cols = ['type', 'month_start', 'day_of_week_start']\n",
    "\n",
    "# target_col = 'score'\n",
    "\n",
    "\n",
    "time_col = 'time_col' # Время привлечения (технический столбец)\n",
    "instance_col = 'partner' # Столбец, опредедяющий одну сущность в данных (технический столбец)\n",
    "\n",
    "num_cols = ['time_left'] # Числовые переменные (например, сколько дней осталось до начала таргета)\n",
    "cat_cols = [] # Категориальные переменные (например, месяц привлечения)\n",
    "\n",
    "fixed_num_cols = [] # Фиксированные числовые переменные (например, время начала работы партнера)\n",
    "fixed_cat_cols = ['type'] #  категориальные переменные (например, тип партнера, он не зависит от времени)\n",
    "\n",
    "target_col = 'score' # Целевая переменная\n",
    "\n",
    "fixed_cols = fixed_num_cols + fixed_cat_cols # Все фиксированные столбцы\n",
    "non_fixed_cols = num_cols + cat_cols # Все нефиксированные столбцы\n",
    "dense_cols = num_cols + fixed_num_cols # Все числовые столбцы\n",
    "non_dense_cols = cat_cols + fixed_cat_cols # Все категориальные столбцы\n",
    "\n",
    "has_num = len(num_cols) != 0 # Есть ли в данных числовые переменные \n",
    "has_cat = len(cat_cols) != 0 # Есть ли в данных категориальные переменные \n",
    "has_fixed_num = len(fixed_num_cols) != 0 # Есть ли в данных фиксированные числовые переменные \n",
    "has_fixed_cat = len(fixed_cat_cols) != 0 # Есть ли в данных фиксированные категориальные переменные "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "643ed25b-2374-406f-b4c8-6c93a1a7f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "di_features = {} # Словарь с переменными\n",
    "\n",
    "di_features['cat_cols'] = cat_cols\n",
    "di_features['num_cols'] = num_cols\n",
    "di_features['time_col'] = time_col\n",
    "di_features['instance_col'] = instance_col\n",
    "di_features['target_col'] = target_col\n",
    "di_features['fixed_num_cols'] = fixed_num_cols\n",
    "di_features['fixed_cat_cols'] = fixed_cat_cols\n",
    "di_features['has_num'] = has_num\n",
    "di_features['has_cat'] = has_cat\n",
    "di_features['has_fixed_num'] = has_fixed_num\n",
    "di_features['has_fixed_cat'] = has_fixed_cat\n",
    "di_features['dense_cols'] = dense_cols\n",
    "di_features['non_dense_cols'] = non_dense_cols\n",
    "\n",
    "\n",
    "\n",
    "with open('constants/di_features.pkl', 'wb') as f:\n",
    "    pickle.dump(di_features, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d986b57-bb1c-4fb2-9b1b-510d8515cc80",
   "metadata": {},
   "source": [
    "# RNN processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7f8e23-2742-4b5c-bd36-e677b0636034",
   "metadata": {},
   "source": [
    "Подготовка датасета для подачи в RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8006c32-ef64-4758-8d26-716907e553d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    number_of_bins_for_num_cols = 12 # На сколько бинов разбивать числовые переменные\n",
    "    max_length = 50 # Максимальная длина (если больше, берем последние 50)\n",
    "    num_partitions_train = num_partitions # Сколько партиций в трейне\n",
    "    num_partitions_val = 1 # Сколько партиций в валидации\n",
    "    num_partitions_test = 1 # Сколько партиций в тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02eef5d9-5d90-4fcd-be00-50a061c86aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Нарезаем числовые фичи на равные по численности промежутки (точнее, пока сохраняем границы)\n",
    "\n",
    "num_bins = cfg.number_of_bins_for_num_cols\n",
    "\n",
    "dense_features_buckets = dict()\n",
    "\n",
    "for feat in dense_cols:\n",
    "    if feat in num_cols:\n",
    "        dense_features_buckets[feat]=pd.qcut(X_train_base[feat], num_bins, labels=False, retbins=True, duplicates='drop')[1]\n",
    "    elif feat in fixed_num_cols:\n",
    "        dense_features_buckets[feat]=pd.qcut(X_train_base.drop_duplicates(subset=[instance_col])[feat], \n",
    "                                             num_bins, labels=False, retbins=True, duplicates='drop')[1]\n",
    "\n",
    "with open('constants/dense_features_buckets.pkl', 'wb') as f:\n",
    "    pickle.dump(dense_features_buckets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a21cb14-ccb2-4475-b222-6afff6245174",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count\n",
       "1      767\n",
       "2      467\n",
       "3      355\n",
       "4      272\n",
       "5      215\n",
       "      ... \n",
       "480      2\n",
       "556      1\n",
       "684      1\n",
       "685      1\n",
       "906      1\n",
       "Name: count, Length: 192, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Встречаемость числа привлечений (например, у 767 партнеров по одному привлечению)\n",
    "lens_count=X_train_base[instance_col].value_counts().value_counts().sort_index()\n",
    "lens_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbfb5859-85bd-48ef-b0b9-11892e22f41a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Мало у кого больше 50 привлечений\n",
    "lens_count.loc[lens_count.index > cfg.max_length].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4ea3bd0-2744-422d-a08f-5dbc3e1f2519",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 13, 16, 21, 30, 46, 50])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = cfg.max_length\n",
    "\n",
    "lens=X_train_base[instance_col].value_counts()\n",
    "\n",
    "# Разобьем длины на 25 частей. Для каждой части выбирается максимальная длина M. Тогда любая последовательность из этой\n",
    "# будет подвергаться паддингу до длина M.\n",
    "pad_borders=pd.qcut(lens, 25, labels=False, retbins=True, duplicates='drop')[1]\n",
    "pad_borders=np.append(pad_borders, max_length)\n",
    "pad_borders.sort()\n",
    "pad_borders = pad_borders[pad_borders<=max_length]\n",
    "pad_borders=pad_borders.astype('int')\n",
    "pad_borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80f16a15-af63-49eb-b1af-455f825e6bc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keys=list(range(1, lens_count[lens_count.index<=max_length].index[-1]+1))\n",
    "values=[1]\n",
    "for i in range(1, len(pad_borders)):\n",
    "    values+=[pad_borders[i]]*(pad_borders[i]-pad_borders[i-1])\n",
    "length_to_pad=dict(zip(keys, values)) # Длина -> Длина с паддингом\n",
    "with open('constants/length_to_pad.pkl', 'wb') as f:\n",
    "    pickle.dump(length_to_pad, f)\n",
    "# length_to_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad29db8-a3d7-49bb-9106-de58d4b9e18c",
   "metadata": {},
   "source": [
    "# Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89c36170-34e3-4db5-b52b-ba5ae6cc19ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_partitions(df, path, num_partitions):\n",
    "    \"\"\"\n",
    "    Создает и сохраняет партиции для валидации и теста (необходимо для больших датасетов)\n",
    "    :param df: pd.DataFrame (Данные)\n",
    "    :param path: str (Куда сохранять)\n",
    "    :param num_partitions: int (Сколько партиций делать)\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    ids=sorted(df[instance_col].unique()) # Все ID\n",
    "    count_ids=len(ids)\n",
    "\n",
    "    for i in tqdm(range(num_partitions)):\n",
    "        index_to_write=ids[int(count_ids*i/num_partitions):int(count_ids*(i+1)/num_partitions)] # Берем 1/num_partitions долю от всех ID\n",
    "        data=df[df[instance_col].isin(index_to_write)]\n",
    "        num=str(i)\n",
    "        if len(num)==1:\n",
    "            num='0'+num\n",
    "        data.to_parquet(f'{path}/part_{num}')\n",
    "        \n",
    "        \n",
    "        \n",
    "def write_partitions_train(df, path, num_partitions):\n",
    "    \"\"\"\n",
    "    Сохраняет партиции для train и train_full (для них уже готовы партиции)\n",
    "    :param df: pd.DataFrame (Данные)\n",
    "    :param path: str (Куда сохранять)\n",
    "    :param num_partitions: int (Сколько партиций делать)\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    for i in range(num_partitions):\n",
    "        data = df[df.partition == i]\n",
    "        num=str(i)\n",
    "        if len(num)==1:\n",
    "            num='0'+num\n",
    "        data.to_parquet(f'{path}/part_{num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68c197fd-2f5f-4063-a77e-732fe8aa10df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 32.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 35.51it/s]\n"
     ]
    }
   ],
   "source": [
    "write_partitions_train(X_train, 'partitions/train', num_partitions=cfg.num_partitions_train)\n",
    "write_partitions_train(X_train_full, 'partitions/train_full', num_partitions=cfg.num_partitions_train)\n",
    "write_partitions(X_val, 'partitions/val', num_partitions=cfg.num_partitions_val)\n",
    "write_partitions(X_test, 'partitions/test', num_partitions=cfg.num_partitions_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68f041a-d107-4694-adc3-492b226d4838",
   "metadata": {},
   "source": [
    "# Uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93abb746-3155-49ea-8c3b-062d136e50e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2718.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Уникальные значения фичей при подаче в нейронную сеть\n",
    "\n",
    "uniques = defaultdict(set)\n",
    "\n",
    "for feat in tqdm(fixed_cat_cols + cat_cols):\n",
    "    uniques[feat] = X_train_base[feat].unique()\n",
    "    \n",
    "for feat in num_cols + fixed_num_cols:\n",
    "    uniques[feat]=set(range(0, len(dense_features_buckets[feat])-1)) # Число границ - 1\n",
    "\n",
    "    \n",
    "with open('constants/uniques.pkl', 'wb') as f:\n",
    "     pickle.dump(uniques, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e168ff-f80f-4ccc-b052-066f02d5d075",
   "metadata": {},
   "source": [
    "## Buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4757ce-e226-4f7f-9c58-7d29dccf3ac0",
   "metadata": {},
   "source": [
    "Создаем бакеты, которые будем подгружать при обучении нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d598c8e8-a1ff-4628-a000-30b8c4d47107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open('constants/length_to_pad.pkl', 'rb') as f:\n",
    "#     length_to_pad = pickle.load(f)\n",
    "    \n",
    "# with open('constants/dense_features_buckets.pkl', 'rb') as f:\n",
    "#     dense_features_buckets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b7b8a9c-bfa8-48fb-a25d-eb1399e649d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_buckets_from_actions(path_to_dataset, save_to_path, frame_with_ids = None, \n",
    "                                     num_parts_to_preprocess_at_once: int = 1, \n",
    "                                     num_parts_total=10, has_target=False):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Преобразует датасет в бакеты, готовые для подачи в даталоадер\n",
    "    Читает num_parts_to_preprocess_at_once частей датасета в память\n",
    "    Преобразует вещественные и численные признаки к категориальным (используя np.digitize и подготовленные бины)\n",
    "    Формирует фрейм с транзакциями в виде последовательностей с помощью transform_actions_to_sequences.\n",
    "    Реализует технику sequence_bucketing и сохраняет словарь обработанных последовательностей в .pkl файл\n",
    "    \n",
    "    :param path_to_dataset: str (Где партиции сохранены)\n",
    "    :param save_to_path: str (Куда сохранять бакеты)\n",
    "    :param frame_with_ids: pd.DataFrame, optional (DataFrame с индексами. По сути, к нему мерджим наши последовательные данные)\n",
    "    :param num_parts_total: int (Всего партиций)\n",
    "    :param has_target: bool (Есть таргет или нет)\n",
    "    :return: None\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    block = 0\n",
    "    for step in range(0, num_parts_total, num_parts_to_preprocess_at_once):\n",
    "        actions_frame = read_parquet_dataset_from_local(path_to_dataset, step, num_parts_to_preprocess_at_once, \n",
    "                                                             verbose=False)\n",
    "        \n",
    "        \n",
    "        for dense_col in dense_cols:\n",
    "            # Разбиваем числовые фичи на бины\n",
    "            actions_frame[dense_col] = np.digitize(actions_frame[dense_col], bins=dense_features_buckets[dense_col])\n",
    "            # Правим бин, если выходим за границы:\n",
    "            actions_frame[dense_col] = actions_frame[dense_col].apply(lambda x: max(1, x))\n",
    "            actions_frame[dense_col] = actions_frame[dense_col].apply(lambda x: min(len(dense_features_buckets[dense_col])-1, x)) - 1\n",
    "            \n",
    "        \n",
    "        # Переводимм датасет в последовательные данные (для каждого партнера имеем последовательность привлечений)\n",
    "        seq = transform_actions_to_sequences(actions_frame, num_last_actions=max_length,\n",
    "                                                 di_features=di_features)\n",
    "        \n",
    "        \n",
    "        if 'partition' in actions_frame:\n",
    "            assert actions_frame['partition'].nunique() == 1\n",
    "            partition = actions_frame['partition'].iloc[0]\n",
    "        \n",
    "        if len(num_cols):\n",
    "            seq['sequence_length'] = seq['num_cols'].apply(lambda x: len(x[0])) # Длина последовательности\n",
    "        else:\n",
    "            seq['sequence_length'] = seq['cat_cols'].apply(lambda x: len(x[0]))\n",
    "        \n",
    "\n",
    "        if frame_with_ids is not None:\n",
    "            if 'partition' in actions_frame:\n",
    "                seq = seq.merge(frame_with_ids[frame_with_ids.partition == partition], on='partner')\n",
    "            else:\n",
    "                seq = seq.merge(frame_with_ids, on='partner')\n",
    "\n",
    "        block_as_str = str(block)\n",
    "        if len(block_as_str) == 1:\n",
    "            block_as_str = '00' + block_as_str\n",
    "        else:\n",
    "            block_as_str = '0' + block_as_str\n",
    "            \n",
    "            \n",
    "        # Наконец, создаем бакеты\n",
    "        processed_fragment =  create_padded_buckets(seq, length_to_pad, has_target=has_target, \n",
    "                                                    save_to_file_path=os.path.join(save_to_path, \n",
    "                                                                                   f'processed_chunk_{block_as_str}.pkl'),\n",
    "                                                   di_features=di_features)\n",
    "        block += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7fcb1e2-b4b4-4e3c-bc9e-e140c8e47fb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: buckets/train: No such file or directory\n",
      "BUCKETS CREATED!\n"
     ]
    }
   ],
   "source": [
    "!rm -r 'buckets/train'\n",
    "!mkdir 'buckets/train'\n",
    "\n",
    "create_buckets_from_actions('partitions/train', \n",
    "                                save_to_path='buckets/train',\n",
    "                                frame_with_ids=y_train, num_parts_to_preprocess_at_once=1, \n",
    "                                 num_parts_total=cfg.num_partitions_train, has_target=True)\n",
    "print('BUCKETS CREATED!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a7d54be-e66d-4e5e-bcbb-ce6cc968d3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: buckets/train_full: No such file or directory\n",
      "BUCKETS CREATED!\n"
     ]
    }
   ],
   "source": [
    "!rm -r 'buckets/train_full'\n",
    "!mkdir 'buckets/train_full'\n",
    "\n",
    "create_buckets_from_actions('partitions/train_full', \n",
    "                                save_to_path='buckets/train_full',\n",
    "                                frame_with_ids=y_train_full, num_parts_to_preprocess_at_once=1, \n",
    "                                 num_parts_total=cfg.num_partitions_train, has_target=True)\n",
    "print('BUCKETS CREATED!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d29648a-d658-436f-bc60-0542ac3178ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: buckets/val: No such file or directory\n",
      "BUCKETS CREATED!\n"
     ]
    }
   ],
   "source": [
    "!rm -r 'buckets/val'\n",
    "!mkdir 'buckets/val'\n",
    "\n",
    "create_buckets_from_actions('partitions/val', \n",
    "                                save_to_path='buckets/val',\n",
    "                                frame_with_ids=y_val, num_parts_to_preprocess_at_once=1, \n",
    "                                 num_parts_total=cfg.num_partitions_val, has_target=True)\n",
    "print('BUCKETS CREATED!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45d21a3e-fd6a-4028-a9c8-a4083fb15ef8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: buckets/test: No such file or directory\n",
      "BUCKETS CREATED!\n"
     ]
    }
   ],
   "source": [
    "!rm -r 'buckets/test'\n",
    "!mkdir 'buckets/test'\n",
    "\n",
    "create_buckets_from_actions('partitions/test', \n",
    "                                save_to_path='buckets/test',\n",
    "                                frame_with_ids=None, num_parts_to_preprocess_at_once=1, num_parts_total=cfg.num_partitions_test, has_target=False)\n",
    "print('BUCKETS CREATED!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
